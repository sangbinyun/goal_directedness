{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env('LANGCHAIN_TRACING_V2')\n",
    "_set_env('LANGCHAIN_ENDPOINT')\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"problem_decomposition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test config file\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--mode', type=str, default='train')\n",
    "parser.add_argument('--data_file', type=str)\n",
    "parser.add_argument('--glove_word_file', type=str, default=glove_word_file)\n",
    "parser.add_argument('--save', type=str, default='HOTPOT')\n",
    "\n",
    "config = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph structure\n",
    "from graph_builder import build_graph\n",
    "ExperimentName = 'test'\n",
    "graph = build_graph(ExperimentName)\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_set = load_dataset(\"hotpot_qa\", 'distractor', split='train', trust_remote_code=True)\n",
    "dev_set = load_dataset(\"hotpot_qa\", 'distractor', split='validation', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_set[0]\n",
    "\n",
    "# Extract data info\n",
    "id = data['id']\n",
    "question = data['question']\n",
    "answer = data['answer']\n",
    "context = [\n",
    "    \"{}: {}\".format(title, \" \".join(sentences)) \n",
    "    for title, sentences in zip(data['context']['title'], data['context']['sentences'])\n",
    "]\n",
    "\n",
    "# Invoke the graphs\n",
    "thread = {\"configurable\": {\"thread_id\": id}}\n",
    "prompt = {\n",
    "    'messages': question,\n",
    "    'context': context\n",
    "}\n",
    "response = graph.invoke(prompt, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": 22}}\n",
    "prompt = {\n",
    "    'messages': 'hi',\n",
    "    'context': 'hi'\n",
    "}\n",
    "response = graph.invoke(prompt, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='a5ad1ae9-6266-4c89-857c-0e8d606090ab'),\n",
       " AIMessage(content='To address the original problem effectively, we need to follow a structured approach by synthesizing the solutions from the sub-problems:\\n\\n1. **Identify the core objective and constraints**:\\n   - The core objective is to verify, refine, and break down the given problem.\\n   - Constraints may include time limitations, resource availability, and any specific requirements provided.\\n\\n2. **Check if the problem is well-defined with clear success criteria**:\\n   - Ensure that the problem statement is clear, concise, and includes measurable success criteria to determine when the problem is solved.\\n\\n3. **Highlight key assumptions and prerequisites**:\\n   - Identify any assumptions made during the analysis process and list out the prerequisites needed to solve the problem effectively.\\n\\n4. **Reformulate if needed to make more precise and actionable**:\\n   - Refine the problem statement if necessary to make it more specific, actionable, and easier to address.\\n\\n5. **Identify the main components that need to be solved**:\\n   - Break down the problem into its main components, such as identifying objectives, constraints, dependencies, and sub-goals.\\n\\n6. **Arrange sub-problems in a vertical sequence with dependencies**:\\n   - Organize the sub-problems in a logical sequence, considering dependencies between them to ensure a systematic approach to solving the overall problem.\\n\\n7. **Further decompose sub-problems that require multiple steps**:\\n   - For sub-problems that involve multiple steps or complexities, break them down further into smaller, more manageable tasks.\\n\\n8. **Specify dependencies between sub-problems**:\\n   - Clearly define the dependencies between sub-problems to understand the order in which they need to be addressed for successful problem resolution.\\n\\nBy following these steps and synthesizing the solutions from each sub-problem, we can create a comprehensive solution that effectively verifies, refines, and breaks down the given problem. This approach ensures a structured and systematic way to address the original problem while considering all relevant aspects and dependencies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 398, 'prompt_tokens': 237, 'total_tokens': 635, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2deaa7f0-3c49-4869-84df-d5b5e57e29ba-0', usage_metadata={'input_tokens': 237, 'output_tokens': 398, 'total_tokens': 635, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(thread).values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goal-directedness-7eAwMRxE-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
